---
title: "p8105_hw5_fp2513"
output: github_document
date: "2024-11-07"
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(rvest)
```


## Problem 1

```{r}
birthday = sample(1:365, 10, replace = TRUE) %>% print()

if (any(duplicated(birthday))) {
  cat("TRUE")
} else {
  cat("FALSE")
}
```

```{r}
check_duplicate_birthdays = function(n) {  
  
  birthdays = sample(1:365, n, replace = TRUE)
 
    has_duplicates = any(duplicated(birthdays))

    return(has_duplicates)
   
}

n = 10
result = check_duplicate_birthdays(n)
cat("Do at least two people share a birthday?", result, n)

```

For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. Make a plot showing the probability as a function of group size, and comment on your results.


```{r}
n_list = 2:50

output = vector("list", length = length(n_list))

for (i in seq_along(n_list)) {
  
  output[[i]] <- rerun(10000, check_duplicate_birthdays(n = n_list[i])) %>%
    unlist() %>%
    as.data.frame() %>%
    setNames(paste0("group_size_", n_list[i]))
}

birthday_result_df = bind_cols(output)
averages = colMeans(birthday_result_df)

average_birthday_dup_df = 
  data.frame(
  group_size = n_list,
  average = averages
)

ggplot(average_birthday_dup_df, aes(x = group_size, y = average)) +
  geom_point() +
  labs(
    title = "Probability of At Least Two People Sharing a Birthday",
    x = "Group Size (n)",
    y = "Probability"
  ) +
  theme_minimal() 

```

The plot follows a sigmoidal curve. 

Where:
At small group sizes (e.g., between 2 and 10 people), the probability of at least two people sharing a birthday starts off low. For very small groups, the probability is almost zero.

As group size increases, the probability increases rapidly. 

For larger group sizes, the curve begins to level off and probability approaches 1 (or 100%) because, with enough people, it becomes almost certain that at least two will share a birthday.


## Problem 2

```{r}
sim_power = function(samp_size = 30, mu = 0, sigma = 5, num_simulations = 5000, alpha = 0.05) {  
  
    run_simulation = function() {

          sample_data = rnorm(samp_size, mean = mu, sd = sigma)
          
          test_result = t.test(sample_data, mu = 0)
          
          result = broom::tidy(test_result)
    return(result)
    }
    
      results = replicate(num_simulations, run_simulation(), simplify = FALSE)

        results_df = bind_rows(results)

          power = mean(results_df$p.value < alpha)

    return(power)
}

sim_power_result = sim_power()
cat("Estimated power of the one-sample t-test: ", sim_power_result, n)
```


```{r}
sim_power = function(samp_size = 30, mu_values = c(0, 1, 2, 3, 4, 5, 6), sigma = 5, num_simulations = 5000, alpha = 0.05) {  
  
  # Function to run one single power simulation
  run_simulation = function(mu) {
    sample_data = rnorm(samp_size, mean = mu, sd = sigma)
    test_result = t.test(sample_data, mu = 0)
    result = broom::tidy(test_result)
    return(result)
  }
  
  # Looping through each value of mu and running power simulations
  power_results = sapply(mu_values, function(mu) {
    results = replicate(num_simulations, run_simulation(mu), simplify = FALSE)
    results_df = bind_rows(results)
    power = mean(results_df$p.value < alpha)
    return(power)
  })
  
  # returning the result of power for each mu
  names(power_results) = mu_values
  return(power_results)
}

# running the simulation overall
sim_power_result = sim_power()
cat("Estimated power of the one-sample t-test for each value of mu: \n")
print(sim_power_result)

```

```{r}
sim_power_df = data.frame(
  mu = as.numeric(names(sim_power_result)),
  power = sim_power_result
)

ggplot(sim_power_df, aes(x = mu, y = power)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Power of the One-Sample t-Test",
       x = "True Value of mu",
       y = "Power (Proportion of Null Rejected)") +
  theme_minimal() 
```

Plots starts with low power when mu = 0 (since it is where the null hypothesis is true). But as the true mean moves away from 0, effect size increases, the power increases. 

At small deviations from 0, such as mu = 1, the power is still relatively low and likely due to that it cannot detect the difference between null and alternative. 

With increasing power this means that the test becomes more likely to reject the null hypothesis as the difference between the null hypothesis and the true mean grows.

**showing the average estimate of sample mean vs true mean**

```{r}
sim_mu_estimate = function(samp_size = 30, mu_values = c(0, 1, 2, 3, 4, 5, 6), sigma = 5, num_simulations = 5000) {  
  
  run_simulation = function(mu) {
    sample_data = rnorm(samp_size, mean = mu, sd = sigma)
    # Calculate  sample mean 
    sample_mean = mean(sample_data)
    return(sample_mean)
  }
  
  mu_estimates = sapply(mu_values, function(mu) {
    estimates = replicate(num_simulations, run_simulation(mu))
    avg_estimate = mean(estimates)  
    return(avg_estimate)
  })
  
  names(mu_estimates) = mu_values
  return(mu_estimates)
}

sim_mu_result = sim_mu_estimate()

mu_estimate_df = data.frame(
  mu = as.numeric(names(sim_mu_result)),
  avg_estimate = sim_mu_result
)

ggplot(mu_estimate_df, aes(x = mu, y = avg_estimate)) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Average Estimate of μ̂ vs True Value of μ",
       x = "True Value of μ",
       y = "Average Estimate of μ̂") +
  theme_minimal() 


```

**plot for the average estimate of sample mu only in samples for which the null was rejected on the y axis and the true value of mu on the x axis**

```{r}

sim_power = function(samp_size = 30, mu = 0, sigma = 5, num_simulations = 5000, alpha = 0.05) {  
  run_simulation = function() {
    sample_data = rnorm(samp_size, mean = mu, sd = sigma)
    test_result = t.test(sample_data, mu = 0)
    result = broom::tidy(test_result)
    return(result)
  }
  
  results = replicate(num_simulations, run_simulation(), simplify = FALSE)
  results_df = bind_rows(results)
  
  # Choosing the results where the null hypothesis is rejected
  rejected_null = results_df[results_df$p.value < alpha, ]
  
  # Calculate the average of sample means for rejected nulls
  avg_mu_rejected = mean(rejected_null$estimate)
  
  return(avg_mu_rejected)
}

# Set of true mu values for simulation
mu_values = c(1, 2, 3, 4, 5, 6)

# Run the simulation for each mu
avg_mu_rejected_values = sapply(mu_values, function(mu) {
  sim_power(samp_size = 30, mu = mu, sigma = 5, num_simulations = 5000, alpha = 0.05)
})

results_df = data.frame(
  True_mu = mu_values,
  Avg_mu_rejected = avg_mu_rejected_values
)

ggplot(results_df, aes(x = True_mu, y = Avg_mu_rejected)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Sample Mean for Samples Where Null Was Rejected",
    x = "True mean",
    y = "Average sample mean (Only Rejected Null)"
  ) +
  theme_minimal()


```

**Is the sample average of the sample mean (mu hat) across the tests for which the null is rejected approximately equal to the true value of mean? Why or why not?**


The sample average of the sample mean (mu hat) of the tests where the null hypothesis is rejected is not necessarily equal to the true value of the true mean (mu). 

One reason is because in taking the sample average of the sample mean of the tests where the null hypothesis is rejected is ultimately a subset of all the tests which were performed. Because it is a subset, it is biased and likely over-represents those sample means that were extreme and lead to very small p-values (that rejected the null hypothesis). This focus on the cases where only the null hypothesis was rejected means that there is a biased selection for sample means that are farther away from zero. Therefore, a overestimation compared to the true value of the true mean (mu). 

In the case here, when the true mean is as a large as 6, the difference between the sample mean and the null hypothesis (0) is substantial. Thus making it increasing likely that the null hypothesis will be rejected. As a result, the bias mentioned due to selecting only the rejected cases becomes minimal, and the sample mean closely approximates the true mean. 

Hence the graph accurately depicts the convergence between the true mean and the sample mean in simulations for larger true mean values (with large effect size and sufficient sample size, n = 30). 


## Problem 3

```{r}
homicide_df = read_csv(file = "data/homicide-data.csv", na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city,", ", state)
  ) %>% 
  group_by(city) %>% 
  mutate(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  ) %>%
  ungroup()

```

```{r}
baltimore_data = homicide_df %>%
  filter(city_state == "Baltimore, MD")

B_unsolved_homicides = sum(baltimore_data$disposition %in% c("Closed without arrest", "Open/No arrest"))
B_total_homicides = nrow(baltimore_data)

prop_test_Baltimore = prop.test(B_unsolved_homicides, B_total_homicides)

tidy_prop_test_Baltimore = broom::tidy(prop_test_Baltimore)

Bal_estimated_proportion = tidy_prop_test_Baltimore$estimate
Bal_conf_int_lower = tidy_prop_test_Baltimore$conf.low
Bal_conf_int_upper = tidy_prop_test_Baltimore$conf.high

cat("Estimated proportion of unsolved homicides: ", Bal_estimated_proportion, "\n")
cat("95% Confidence interval: (", Bal_conf_int_lower, ", ", Bal_conf_int_upper, ")\n")

```

